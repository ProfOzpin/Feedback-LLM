{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "07e94a1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                       Misconception Misconception ID  \\\n",
      "0  when students don't understand how to represen...            MaE01   \n",
      "1  when students don't understand how to represen...            MaE01   \n",
      "2  when students don't understand how to represen...            MaE01   \n",
      "3  when students don't understand how to represen...            MaE01   \n",
      "4  Students misunderstand proportional relationsh...            MaE02   \n",
      "\n",
      "          Topic  Example Number  \\\n",
      "0  Number sense               1   \n",
      "1  Number sense               2   \n",
      "2  Number sense               3   \n",
      "3  Number sense               4   \n",
      "4  Number sense               1   \n",
      "\n",
      "                                            Question Incorrect Answer  \\\n",
      "0  What part is shaded?\\nWrite a Fraction\\n(Exerc...              1/3   \n",
      "1  What part is shaded?\\nWrite a Fraction\\n(Exerc...              2/1   \n",
      "2  What part is shaded?\\nWrite a Fraction\\n(Exerc...              2/2   \n",
      "3  What part is shaded?\\nWrite a Fraction\\n(Exerc...              3/1   \n",
      "4  What part is shaded?\\nWrite a Fraction\\n(Exerc...              1/5   \n",
      "\n",
      "  Correct Answer Question image Learner Answer image Correct Answer image  \\\n",
      "0            1/4      MaE1-Ex1Q           MaE1-Ex1LA                        \n",
      "1            2/3      MaE1-Ex2Q           MaE1-Ex2LA                        \n",
      "2            1/2      MaE1-Ex3Q           MaE1-Ex3LA                        \n",
      "3            3/4      MaE1-Ex4Q           MaE1-Ex4LA                        \n",
      "4            1/4      MaE2-Ex1Q           MaE2-Ex1LA                        \n",
      "\n",
      "          Source Explanation  \n",
      "0  Ashlock, 2006              \n",
      "1  Ashlock, 2006              \n",
      "2  Ashlock, 2006              \n",
      "3  Ashlock, 2006              \n",
      "4  Ashlock, 2006              \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset from the JSON file\n",
    "df = pd.read_json('data.json')\n",
    "\n",
    "# Display the first few rows to verify it loaded correctly\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8fb418ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dataset shape: (220, 12)\n",
      "Text-only dataset shape: (199, 12)\n"
     ]
    }
   ],
   "source": [
    "# Filter for rows where 'Question image' is empty, meaning no image is required\n",
    "text_only_df = df[df['Question image'] == ''].copy()\n",
    "\n",
    "# Reset the index of the new DataFrame\n",
    "text_only_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Display the shape of the original and the new text-only DataFrame\n",
    "print(f\"Original dataset shape: {df.shape}\")\n",
    "print(f\"Text-only dataset shape: {text_only_df.shape}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "be72690d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prepared dataset saved to prepared_dataset.csv\n"
     ]
    }
   ],
   "source": [
    "# Save the cleaned data to a new CSV file\n",
    "text_only_df.to_csv('prepared_dataset.csv', index=False)\n",
    "\n",
    "print(\"Prepared dataset saved to prepared_dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "27caf5aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully created training and validation files.\n",
      "Training set dimensions: (159, 12)\n",
      "Validation set dimensions: (40, 12)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load the cleaned, text-only dataset\n",
    "try:\n",
    "    prepared_df = pd.read_csv('prepared_dataset.csv')\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: 'prepared_dataset.csv' not found.\")\n",
    "    print(\"Please run the previous data preparation steps first.\")\n",
    "    # As a fallback for demonstration, create a dummy dataframe\n",
    "    data = [{'Misconception ID': f'M{i}', 'Question': f'Q{i}', 'Incorrect Answer': f'IA{i}', 'Correct Answer': f'CA{i}'} for i in range(100)]\n",
    "    prepared_df = pd.DataFrame(data)\n",
    "\n",
    "\n",
    "# Split the data into training (80%) and validation (20%) sets\n",
    "# Using random_state=42 ensures that the split is the same every time we run the code\n",
    "train_df, validation_df = train_test_split(\n",
    "    prepared_df,\n",
    "    test_size=0.2,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Save the datasets to their respective CSV files\n",
    "train_df.to_csv('train_data.csv', index=False)\n",
    "validation_df.to_csv('validation_data.csv', index=False)\n",
    "\n",
    "print(f\"Successfully created training and validation files.\")\n",
    "print(f\"Training set dimensions: {train_df.shape}\")\n",
    "print(f\"Validation set dimensions: {validation_df.shape}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d5d5b000",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yousy\\AppData\\Local\\Temp\\ipykernel_5556\\3112595173.py:9: DtypeWarning: Columns (17) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file_path, encoding='latin-1')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Unique Skill Names in the ASSISTments Dataset ---\n",
      "Absolute Value\n",
      "Addition Whole Numbers\n",
      "Addition and Subtraction Fractions\n",
      "Addition and Subtraction Integers\n",
      "Addition and Subtraction Positive Decimals\n",
      "Algebraic Simplification\n",
      "Algebraic Solving\n",
      "Angles - Obtuse, Acute, and Right\n",
      "Angles on Parallel Lines Cut by a Transversal\n",
      "Area Circle\n",
      "Area Irregular Figure\n",
      "Area Parallelogram\n",
      "Area Rectangle\n",
      "Area Trapezoid\n",
      "Area Triangle\n",
      "Box and Whisker\n",
      "Calculations with Similar Figures\n",
      "Choose an Equation from Given Information\n",
      "Circle Graph\n",
      "Circumference \n",
      "Complementary and Supplementary Angles\n",
      "Computation with Real Numbers\n",
      "Congruence\n",
      "Conversion of Fraction Decimals Percents\n",
      "Counting Methods\n",
      "D.4.8-understanding-concept-of-probabilities\n",
      "Distributive Property\n",
      "Divisibility Rules\n",
      "Division Fractions\n",
      "Effect of Changing Dimensions of a Shape Prportionally\n",
      "Equation Solving More Than Two Steps\n",
      "Equation Solving Two or Fewer Steps\n",
      "Equivalent Fractions\n",
      "Estimation\n",
      "Exponents\n",
      "Finding Percents\n",
      "Finding Slope From Equation\n",
      "Finding Slope From Situation\n",
      "Finding Slope from Ordered Pairs\n",
      "Fraction Of\n",
      "Greatest Common Factor\n",
      "Histogram as Table or Graph\n",
      "Intercept\n",
      "Interior Angles Figures with More than 3 Sides\n",
      "Interior Angles Triangle\n",
      "Interpreting Coordinate Graphs \n",
      "Least Common Multiple\n",
      "Linear Equations\n",
      "Mean\n",
      "Median\n",
      "Midpoint\n",
      "Mode\n",
      "Multiplication Fractions\n",
      "Multiplication Whole Numbers\n",
      "Multiplication and Division Integers\n",
      "Multiplication and Division Positive Decimals\n",
      "Nets of 3D Figures\n",
      "Number Line\n",
      "Order of Operations +,-,/,* () positive reals\n",
      "Order of Operations All\n",
      "Ordering Fractions\n",
      "Ordering Integers\n",
      "Ordering Positive Decimals\n",
      "Ordering Real Numbers\n",
      "Parts of a Polyomial, Terms, Coefficient, Monomial, Exponent, Variable\n",
      "Pattern Finding \n",
      "Percent Discount\n",
      "Percent Of\n",
      "Percents\n",
      "Perimeter of a Polygon\n",
      "Polynomial Factors\n",
      "Prime Number\n",
      "Probability of Two Distinct Events\n",
      "Probability of a Single Event\n",
      "Proportion\n",
      "Pythagorean Theorem\n",
      "Quadratic Formula to Solve Quadratic Equation\n",
      "Range\n",
      "Rate\n",
      "Reading a Ruler or Scale\n",
      "Recognize Linear Pattern\n",
      "Recognize Quadratic Pattern\n",
      "Reflection\n",
      "Rotations\n",
      "Rounding\n",
      "Scale Factor\n",
      "Scatter Plot\n",
      "Scientific Notation\n",
      "Simplifying Expressions positive exponents\n",
      "Slope\n",
      "Solving Inequalities\n",
      "Solving Systems of Linear Equations\n",
      "Solving Systems of Linear Equations by Graphing\n",
      "Solving for a variable\n",
      "Square Root\n",
      "Stem and Leaf Plot\n",
      "Subtraction Whole Numbers\n",
      "Surface Area Cylinder\n",
      "Surface Area Rectangular Prism\n",
      "Table\n",
      "Translations\n",
      "Unit Conversion Within a System\n",
      "Unit Rate\n",
      "Venn Diagram\n",
      "Volume Cylinder\n",
      "Volume Rectangular Prism\n",
      "Volume Sphere\n",
      "Write Linear Equation from Graph\n",
      "Write Linear Equation from Ordered Pairs\n",
      "Write Linear Equation from Situation\n",
      "\n",
      "Total number of unique skills: 110\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Define the file path for your dataset\n",
    "file_path = 'skill_builder_data.csv'\n",
    "\n",
    "try:\n",
    "    # Load the dataset using pandas, specifying the correct encoding\n",
    "    # 'latin-1' is a common encoding for this dataset that avoids errors\n",
    "    df = pd.read_csv(file_path, encoding='latin-1')\n",
    "\n",
    "    # Extract the 'skill name' column, drop any missing values, and get unique entries\n",
    "    unique_skills = df['skill_name'].dropna().unique()\n",
    "\n",
    "    # Sort the skills alphabetically for easier reading\n",
    "    unique_skills.sort()\n",
    "\n",
    "    # Print each unique skill name\n",
    "    print(\"--- Unique Skill Names in the ASSISTments Dataset ---\")\n",
    "    for skill in unique_skills:\n",
    "        print(skill)\n",
    "\n",
    "    # Print the total count of unique skills\n",
    "    print(f\"\\nTotal number of unique skills: {len(unique_skills)}\")\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: The file was not found at '{file_path}'\")\n",
    "    print(\"Please make sure the CSV file is in the same directory as your script, or provide the full path.\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "def02364",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "skill_name\n",
      "Equation Solving Two or Fewer Steps         24253\n",
      "Percent Of                                  22931\n",
      "Addition and Subtraction Integers           22895\n",
      "Conversion of Fraction Decimals Percents    20992\n",
      "Volume Rectangular Prism                    19489\n",
      "                                            ...  \n",
      "Midpoint                                       32\n",
      "Distributive Property                          18\n",
      "Finding Slope From Situation                    9\n",
      "Reading a Ruler or Scale                        5\n",
      "Finding Slope from Ordered Pairs                5\n",
      "Name: count, Length: 110, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "skill_counts = df['skill_name'].value_counts()\n",
    "print(skill_counts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2fb6cec5",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 0 is out of bounds for axis 0 with size 0",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mIndexError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m template_skills = \u001b[43mdf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgroupby\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mtemplate_id\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mskill_name\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43magg\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalue_counts\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m.\u001b[49m\u001b[43mempty\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m      2\u001b[39m \u001b[38;5;28mprint\u001b[39m(template_skills.head(\u001b[32m10\u001b[39m))\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\yousy\\Documents\\Feedback LLM\\.venv\\Lib\\site-packages\\pandas\\core\\groupby\\generic.py:294\u001b[39m, in \u001b[36mSeriesGroupBy.aggregate\u001b[39m\u001b[34m(self, func, engine, engine_kwargs, *args, **kwargs)\u001b[39m\n\u001b[32m    291\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._python_agg_general(func, *args, **kwargs)\n\u001b[32m    293\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m294\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_python_agg_general\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    295\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n\u001b[32m    296\u001b[39m     \u001b[38;5;66;03m# KeyError raised in test_groupby.test_basic is bc the func does\u001b[39;00m\n\u001b[32m    297\u001b[39m     \u001b[38;5;66;03m#  a dictionary lookup on group.name, but group name is not\u001b[39;00m\n\u001b[32m    298\u001b[39m     \u001b[38;5;66;03m#  pinned in _python_agg_general, only in _aggregate_named\u001b[39;00m\n\u001b[32m    299\u001b[39m     result = \u001b[38;5;28mself\u001b[39m._aggregate_named(func, *args, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\yousy\\Documents\\Feedback LLM\\.venv\\Lib\\site-packages\\pandas\\core\\groupby\\generic.py:327\u001b[39m, in \u001b[36mSeriesGroupBy._python_agg_general\u001b[39m\u001b[34m(self, func, *args, **kwargs)\u001b[39m\n\u001b[32m    324\u001b[39m f = \u001b[38;5;28;01mlambda\u001b[39;00m x: func(x, *args, **kwargs)\n\u001b[32m    326\u001b[39m obj = \u001b[38;5;28mself\u001b[39m._obj_with_exclusions\n\u001b[32m--> \u001b[39m\u001b[32m327\u001b[39m result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_grouper\u001b[49m\u001b[43m.\u001b[49m\u001b[43magg_series\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    328\u001b[39m res = obj._constructor(result, name=obj.name)\n\u001b[32m    329\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._wrap_aggregated_output(res)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\yousy\\Documents\\Feedback LLM\\.venv\\Lib\\site-packages\\pandas\\core\\groupby\\ops.py:864\u001b[39m, in \u001b[36mBaseGrouper.agg_series\u001b[39m\u001b[34m(self, obj, func, preserve_dtype)\u001b[39m\n\u001b[32m    857\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj._values, np.ndarray):\n\u001b[32m    858\u001b[39m     \u001b[38;5;66;03m# we can preserve a little bit more aggressively with EA dtype\u001b[39;00m\n\u001b[32m    859\u001b[39m     \u001b[38;5;66;03m#  because maybe_cast_pointwise_result will do a try/except\u001b[39;00m\n\u001b[32m    860\u001b[39m     \u001b[38;5;66;03m#  with _from_sequence.  NB we are assuming here that _from_sequence\u001b[39;00m\n\u001b[32m    861\u001b[39m     \u001b[38;5;66;03m#  is sufficiently strict that it casts appropriately.\u001b[39;00m\n\u001b[32m    862\u001b[39m     preserve_dtype = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m864\u001b[39m result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_aggregate_series_pure_python\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    866\u001b[39m npvalues = lib.maybe_convert_objects(result, try_float=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m    867\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m preserve_dtype:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\yousy\\Documents\\Feedback LLM\\.venv\\Lib\\site-packages\\pandas\\core\\groupby\\ops.py:885\u001b[39m, in \u001b[36mBaseGrouper._aggregate_series_pure_python\u001b[39m\u001b[34m(self, obj, func)\u001b[39m\n\u001b[32m    882\u001b[39m splitter = \u001b[38;5;28mself\u001b[39m._get_splitter(obj, axis=\u001b[32m0\u001b[39m)\n\u001b[32m    884\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i, group \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(splitter):\n\u001b[32m--> \u001b[39m\u001b[32m885\u001b[39m     res = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    886\u001b[39m     res = extract_result(res)\n\u001b[32m    888\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m initialized:\n\u001b[32m    889\u001b[39m         \u001b[38;5;66;03m# We only do this validation on the first iteration\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\yousy\\Documents\\Feedback LLM\\.venv\\Lib\\site-packages\\pandas\\core\\groupby\\generic.py:324\u001b[39m, in \u001b[36mSeriesGroupBy._python_agg_general.<locals>.<lambda>\u001b[39m\u001b[34m(x)\u001b[39m\n\u001b[32m    322\u001b[39m     alias = com._builtin_table_alias[func]\n\u001b[32m    323\u001b[39m     warn_alias_replacement(\u001b[38;5;28mself\u001b[39m, orig_func, alias)\n\u001b[32m--> \u001b[39m\u001b[32m324\u001b[39m f = \u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    326\u001b[39m obj = \u001b[38;5;28mself\u001b[39m._obj_with_exclusions\n\u001b[32m    327\u001b[39m result = \u001b[38;5;28mself\u001b[39m._grouper.agg_series(obj, f)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 1\u001b[39m, in \u001b[36m<lambda>\u001b[39m\u001b[34m(x)\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m template_skills = df.groupby(\u001b[33m'\u001b[39m\u001b[33mtemplate_id\u001b[39m\u001b[33m'\u001b[39m)[\u001b[33m'\u001b[39m\u001b[33mskill_name\u001b[39m\u001b[33m'\u001b[39m].agg(\u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[43mx\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalue_counts\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m x.empty \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m      2\u001b[39m \u001b[38;5;28mprint\u001b[39m(template_skills.head(\u001b[32m10\u001b[39m))\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\yousy\\Documents\\Feedback LLM\\.venv\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:5401\u001b[39m, in \u001b[36mIndex.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   5398\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_integer(key) \u001b[38;5;129;01mor\u001b[39;00m is_float(key):\n\u001b[32m   5399\u001b[39m     \u001b[38;5;66;03m# GH#44051 exclude bool, which would return a 2d ndarray\u001b[39;00m\n\u001b[32m   5400\u001b[39m     key = com.cast_scalar_indexer(key)\n\u001b[32m-> \u001b[39m\u001b[32m5401\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgetitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   5403\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, \u001b[38;5;28mslice\u001b[39m):\n\u001b[32m   5404\u001b[39m     \u001b[38;5;66;03m# This case is separated from the conditional above to avoid\u001b[39;00m\n\u001b[32m   5405\u001b[39m     \u001b[38;5;66;03m# pessimization com.is_bool_indexer and ndim checks.\u001b[39;00m\n\u001b[32m   5406\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._getitem_slice(key)\n",
      "\u001b[31mIndexError\u001b[39m: index 0 is out of bounds for axis 0 with size 0"
     ]
    }
   ],
   "source": [
    "template_skills = df.groupby('template_id')['skill_name'].agg(lambda x: x.value_counts().index[0] if not x.empty else None)\n",
    "print(template_skills.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3448d219",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "correct\n",
      "0    1.960179\n",
      "1    1.003133\n",
      "Name: attempt_count, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Compare attempt counts for correct vs. incorrect answers for a specific skill\n",
    "skill_data = df[df['skill_name'] == 'Pythagorean Theorem']\n",
    "behavior_comparison = skill_data.groupby('correct')['attempt_count'].mean()\n",
    "print(behavior_comparison)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
